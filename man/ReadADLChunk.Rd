% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ReadADLChunk.R
\name{ReadADLChunk}
\alias{ReadADLChunk}
\title{Reading Source Chunks from the Data Lake}
\usage{
ReadADLChunk(Source = "", From = "", To = "",
  FileExtension = "rdata", Directory = F, Iterate = F)
}
\arguments{
\item{Source}{If the Source parameter is not provided then the interactive mode
requests a numeric selection (n). A user may also supply a string
with one of the following (Source) values:\cr
\tabular{rlll}{
\tab  n \strong{Source}       \tab \strong{Effect} \tab \strong{Data Documentation:}\cr
\tab  1 \emph{Email}          \tab For the Spiceworks Email data \tab \code{\link{TestEmailChunk}}  \cr
\tab  2 \emph{Client}         \tab For the Spiceworks PC Client data \tab \code{\link{TestClientChunk}} \cr
\tab  3 \emph{Networkhv}      \tab For the Spiceworks Network data by hypervisor \tab \code{\link{TestNetworkhvChunk}} \cr
\tab  4 \emph{Networkos}      \tab For the Spiceworks Network data by operating system \tab \code{\link{TestNetworkosChunk}} \cr
\tab  5 \emph{ServerRoles}    \tab For the Spiceworks Server Roles data \tab \code{\link{TestServerRolesChunk}} \cr
\tab  6 \emph{WorkloadDB}     \tab For the Spiceworks Workload data for database products \tab \code{\link{TestWorkloadDBChunk}} \cr
\tab  7 \emph{WorkloadEco}    \tab This chunk lists the virt flag and data type along with Hypervisor and OS for the intersection of Network and VID \tab \code{\link{TestWorkloadEcoChunk}} \cr
\tab  8 \emph{WorkloadHW}     \tab This chunk lists the metadata that we received relating to server hardware. \tab \code{\link{TestWorkloadHWChunk}} \cr
\tab  9 \emph{WorkloadN}      \tab This chunk lists the virt flag and data type along with Hypervisor and OS for the Network style data \tab \code{\link{TestWorkloadNChunk}} \cr
\tab 10 \emph{WorkloadVID}    \tab This chunk lists the virt flag and data type along with Hypervisor and OS for the VID style data \tab \code{\link{TestWorkloadVIDChunk}} \cr
\tab 11 \emph{WorkloadWL}     \tab For the Spiceworks workload data for non-database products \tab \code{\link{TestWorkloadWLChunk}} \cr
\tab 12 \emph{CCMCost}        \tab For the Spiceworks CCM Cost data\cr
\tab 13 \emph{CCMUsage}       \tab For the Spiceworks CCM Usage data\cr
\tab 14 \emph{OnlineServices} \tab For the Spiceworks Online Services Data\cr
\tab 15 \emph{VID}            \tab For the Spiceworks VID Data\cr
\tab 16 \emph{ServerAge}      \tab For the Spiceworks Server Age Data\cr
\tab 17 \emph{Cosmos}         \tab For the Cosmos Data\cr
}}

\item{From}{The timestamp of the first month of data.  If this is not provided this defaults
to 2016M01 but in general the user should select a timestamp.}

\item{To}{The timestamp of the last month of data needed when the user needs to get a range
of timestamps.  If this is left blank then the system returns just the single timestamp provided
in the to parameter.}

\item{FileExtension}{"csv" or "rdata"}

\item{Directory}{If set to TRUE the function returns a data table with a directory
of contents of both the Data Lake and the Cache.  This defaults to FALSE.}

\item{Iterate}{This can be ommitted or used to control what happens during a script run in the IterateScript
function.  If this is called with Iterate = F then when the script is run as part of an iteration this command
will be kept as it is.  When this is called with Iterate = T then when the script is run under iteration the command
will be modified to read just one month of data which will be updated by the iteration.}
}
\value{
Returns a data table:
If the parameter directory = TRUE the table has a directory
of the Data Lake and the local cache.
If directory = FALSE (or was not specified) the table has the requested data.
If the request spanned more than one timestamp all the available
timestamps are returned in one concatenated file.

As a by-product the function leaves copies of the requested
chunks in the local Cache
}
\description{
This function can be used to pull data chunks from the Azure Data Lake where
the TAP data is stored.  It uses a two stage process where the data is downloaded
to a local cache and then read to the working environment.  This means that after
the first call the function will be much faster as it can use the cached data.
It also means that users can analyse data without access to any other resource
such as when travelling.
}
\details{
The function requires the user to select a Spiceworks source and either an individual or
a range of timestamps for which data is required.

The system then checks for net connectivity.  If we have net connectivity
the function requests a directory listing from the Data Lake and compares it to a
directory listing of the local cache.

The system then considers the set of requested data and then generates these sets:
 1. Requested data that can be loaded directly from the Cache
 2. Requested data that is not in the cache but can be copied down from the Data Lake
 3. Requested data that is not available

 After reporting the results the system pulls the files identified in set 2 from the Data
 Lake to the cache and then loads all the available data from the cache.
}
\examples{
ReadADLChunk(Source = "Email", From = "2015M01")
ReadADLChunk(Source = "Email", Directory = TRUE)
}
\seealso{
\code{\link{TAPChunks}}

Other Data Lake Tools: \code{\link{ListADLDirectory}},
  \code{\link{ReadABSFile}}, \code{\link{ReadADLFile}},
  \code{\link{UploadLocallyToADL}}
}
\author{
JTA - The Data Scientists
}
\concept{Data Lake Tools}
